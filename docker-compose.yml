version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: wingman-postgres
    environment:
      POSTGRES_DB: wingman
      POSTGRES_USER: wingman
      POSTGRES_PASSWORD: wingman
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U wingman"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - wingman-network

  # Chroma Vector Store
  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: wingman-chroma
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
    ports:
      - "8001:8000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - wingman-network

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: wingman-backend
    environment:
      # Application
      DEBUG: "false"
      HOST: "0.0.0.0"
      PORT: "8000"
      
      # Slack (load from .env)
      SLACK_BOT_TOKEN: ${SLACK_BOT_TOKEN}
      SLACK_APP_TOKEN: ${SLACK_APP_TOKEN}
      SLACK_SIGNING_SECRET: ${SLACK_SIGNING_SECRET}
      SLACK_USER_TOKEN: ${SLACK_USER_TOKEN:-}
      SLACK_CLIENT_ID: ${SLACK_CLIENT_ID:-}
      SLACK_CLIENT_SECRET: ${SLACK_CLIENT_SECRET:-}
      
      # OpenRouter/OpenAI
      OPENROUTER_API_KEY: ${OPENROUTER_API_KEY:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      LLM_MODEL: ${LLM_MODEL:-openai/gpt-4-turbo-preview}
      
      # Database
      DATABASE_URL: "postgresql://wingman:wingman@postgres:5432/wingman"
      
      # Chroma
      CHROMA_HOST: "chroma"
      CHROMA_PORT: "8000"
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      chroma:
        condition: service_healthy
    volumes:
      - ./backend:/app
    networks:
      - wingman-network
    restart: unless-stopped

  # Slack Bot (separate service for socket mode)
  bot:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: wingman-bot
    command: python run_bot.py
    environment:
      # Slack
      SLACK_BOT_TOKEN: ${SLACK_BOT_TOKEN}
      SLACK_APP_TOKEN: ${SLACK_APP_TOKEN}
      SLACK_SIGNING_SECRET: ${SLACK_SIGNING_SECRET}
      
      # OpenRouter/OpenAI
      OPENROUTER_API_KEY: ${OPENROUTER_API_KEY:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      LLM_MODEL: ${LLM_MODEL:-openai/gpt-4-turbo-preview}
      
      # Database
      DATABASE_URL: "postgresql://wingman:wingman@postgres:5432/wingman"
      
      # Chroma
      CHROMA_HOST: "chroma"
      CHROMA_PORT: "8000"
    depends_on:
      postgres:
        condition: service_healthy
      chroma:
        condition: service_healthy
    volumes:
      - ./backend:/app
    networks:
      - wingman-network
    restart: unless-stopped

  # Frontend Dashboard
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        NEXT_PUBLIC_API_URL: http://localhost:8000
    container_name: wingman-frontend
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:8000
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - wingman-network
    restart: unless-stopped

volumes:
  postgres_data:
  chroma_data:

networks:
  wingman-network:
    driver: bridge
